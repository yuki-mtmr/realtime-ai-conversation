<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Conversation</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            height: 100vh;
            margin: 0;
            background-color: #f0f0f0;
        }
        #toggleAudio {
            font-size: 18px;
            padding: 10px 20px;
            cursor: pointer;
            background-color: #4CAF50;
            color: white;
            border: none;
            border-radius: 5px;
            transition: background-color 0.3s;
        }
        #toggleAudio:hover {
            background-color: #45a049;
        }
        #status {
            margin-top: 20px;
            color: #666;
        }
    </style>
</head>
<body>
    <button id="toggleAudio">Start Audio</button>
    <div id="status"></div>

    <script>
        // Create audio context
        const BUFFER_SIZE = 4800;
        const statusElement = document.getElementById('status');

        class Player {
            constructor() {
                this.playbackNode = null;
            }

            async init(sampleRate) {
                const audioContext = new AudioContext({ sampleRate });
                await audioContext.audioWorklet.addModule("/static/audio-playback-worklet.js");

                this.playbackNode = new AudioWorkletNode(audioContext, "audio-playback-worklet");
                this.playbackNode.connect(audioContext.destination);
            }

            play(buffer) {
                if (this.playbackNode) {
                    this.playbackNode.port.postMessage(buffer);
                }
            }

            stop() {
                if (this.playbackNode) {
                    this.playbackNode.port.postMessage(null);
                }
            }
        }

        class Recorder {
            constructor(onDataAvailable) {
                this.onDataAvailable = onDataAvailable;
                this.audioContext = null;
                this.mediaStream = null;
                this.mediaStreamSource = null;
                this.workletNode = null;
            }

            async start(stream) {
                try {
                    if (this.audioContext) {
                        await this.audioContext.close();
                    }

                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
                    await this.audioContext.audioWorklet.addModule("/static/audio-processor-worklet.js");

                    this.mediaStream = stream;
                    this.mediaStreamSource = this.audioContext.createMediaStreamSource(this.mediaStream);

                    this.workletNode = new AudioWorkletNode(this.audioContext, "audio-processor-worklet");
                    this.workletNode.port.onmessage = event => {
                        this.onDataAvailable(event.data.buffer);
                    };

                    this.mediaStreamSource.connect(this.workletNode);
                    this.workletNode.connect(this.audioContext.destination);
                    statusElement.textContent = "Recording started";
                } catch (error) {
                    console.error('Recorder error:', error);
                    statusElement.textContent = `Error: ${error.message}`;
                    this.stop();
                }
            }

            async stop() {
                if (this.mediaStream) {
                    this.mediaStream.getTracks().forEach(track => track.stop());
                    this.mediaStream = null;
                }

                if (this.audioContext) {
                    await this.audioContext.close();
                    this.audioContext = null;
                }

                this.mediaStreamSource = null;
                this.workletNode = null;
                statusElement.textContent = "Recording stopped";
            }
        }

        // Function to get microphone input and send it to WebSocket
        async function startAudio() {
            try {
                // handle output -> speaker stuff
                const ws = new WebSocket(`ws://${window.location.host}/ws`);

                const audioPlayer = new Player();
                await audioPlayer.init(24000);

                ws.onmessage = event => {
                    try {
                        const data = JSON.parse(event.data);
                        if (data?.type !== 'response.audio.delta') return;

                        const binary = atob(data.delta);
                        const bytes = Uint8Array.from(binary, c => c.charCodeAt(0));
                        const pcmData = new Int16Array(bytes.buffer);

                        audioPlayer.play(pcmData);
                    } catch (error) {
                        console.error('WebSocket message error:', error);
                        statusElement.textContent = `WebSocket error: ${error.message}`;
                    }
                };

                let buffer = new Uint8Array();

                const appendToBuffer = (newData) => {
                    const newBuffer = new Uint8Array(buffer.length + newData.length);
                    newBuffer.set(buffer);
                    newBuffer.set(newData, buffer.length);
                    buffer = newBuffer;
                };

                const handleAudioData = (data) => {
                    const uint8Array = new Uint8Array(data);
                    appendToBuffer(uint8Array);

                    if (buffer.length >= BUFFER_SIZE) {
                        const toSend = new Uint8Array(buffer.slice(0, BUFFER_SIZE));
                        buffer = new Uint8Array(buffer.slice(BUFFER_SIZE));

                        const regularArray = String.fromCharCode(...toSend);
                        const base64 = btoa(regularArray);

                        ws.send(JSON.stringify({type: 'input_audio_buffer.append', audio: base64}));
                    }
                };

                // handle microphone -> input websocket
                const audioRecorder = new Recorder(handleAudioData);
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                await audioRecorder.start(stream);
                statusElement.textContent = "Connected and recording";

            } catch (error) {
                console.error('Error:', error);
                statusElement.textContent = `Error: ${error.message}. Please check your microphone settings.`;
                alert('Error accessing the microphone. Please check your settings and try again.');
            }
        }

        // Button to toggle audio
        const toggleButton = document.getElementById('toggleAudio');
        let isAudioOn = false;

        toggleButton.addEventListener('click', async () => {
            if (!isAudioOn) {
                await startAudio();
                toggleButton.textContent = 'Stop Audio';
                isAudioOn = true;
            } else {
                location.reload(); // 簡単な方法として、ページをリロード
                toggleButton.textContent = 'Start Audio';
                isAudioOn = false;
            }
        });
    </script>
</body>
</html>